{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# A couple requried imports\n",
    "from glob import glob \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tifffile import imread, TiffFile\n",
    "from skimage import io\n",
    "\n",
    "\n",
    "# Importing the deep learning framework\n",
    "from csbdeep.models import CARE, Config\n",
    "\n",
    "from csbdeep.utils import plot_some, plot_history, Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11 channel 1 files and 11 channel 2 files\n"
     ]
    }
   ],
   "source": [
    "base_dir = r'X:\\GautamDey\\2020\\Fast Nup imaging\\separate for denoising'\n",
    "base_path = Path(base_dir)\n",
    "C1_path = Path(base_path/r'C1'/r'raw data')\n",
    "C2_path = Path(base_path/r'C2'/r'raw data')\n",
    "\n",
    "C1_files = sorted(C1_path.rglob('*.tif'))\n",
    "C2_files = sorted(C2_path.rglob('*.tif'))\n",
    "\n",
    "save_dir_C1 = C1_path/f'results'\n",
    "save_dir_C1.mkdir(exist_ok=True)\n",
    "save_dir_C2 = C2_path/f'results'\n",
    "save_dir_C2.mkdir(exist_ok=True)\n",
    "\n",
    "print(f'There are {len(C1_files)} channel 1 files and {len(C2_files)} channel 2 files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:21<00:00,  1.96s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:24<00:00,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "C1_ims = []\n",
    "C1_names = []\n",
    "C2_ims = []\n",
    "C2_names = []\n",
    "for file in tqdm(C1_files):\n",
    "    C1_names.append(file.stem)\n",
    "    T1 = imread(str(file))\n",
    "    C1_ims.append(T1)\n",
    "for file in tqdm(C2_files):\n",
    "    C2_names.append(file.stem)\n",
    "    T2 = imread(str(file))\n",
    "    C2_ims.append(T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0317 07:28:07.381232 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0317 07:28:07.384311 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0317 07:28:07.407856 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0317 07:28:07.440747 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0317 07:28:07.445755 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0317 07:28:07.529825 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0317 07:28:07.530823 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0317 07:28:07.530823 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0317 07:28:07.804584 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "W0317 07:28:07.804584 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "W0317 07:28:07.820207 13388 module_wrapper.py:139] From C:\\Users\\SC\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network weights from 'weights_best.h5'.\n"
     ]
    }
   ],
   "source": [
    "model1 = CARE(config=None, name='noise2noise_C1_norm', basedir='models')\n",
    "model2 = CARE(config=None, name='noise2noise_cut11', basedir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img, mean, std):\n",
    "    return (img - mean)/std\n",
    "\n",
    "def denormalize(img, mean, std):\n",
    "    return (img * std) + mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 11/11 [22:50<00:00, 124.61s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 11/11 [22:43<00:00, 123.93s/it]\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for T in tqdm(C1_ims):\n",
    "    denoised_1 = []\n",
    "    for frame in T:\n",
    "        mean = np.mean(frame)\n",
    "        std = np.std(frame)\n",
    "        pred = denormalize(model1.predict(normalize(frame, mean, std), axes='YX', normalizer=None), mean, std)\n",
    "        denoised_1.append(pred)\n",
    "    io.imsave(f'{save_dir_C1}/{C1_names[counter]}.tif', np.asarray(denoised_1))\n",
    "    counter+=1\n",
    "\n",
    "counter = 0\n",
    "for T in tqdm(C2_ims):\n",
    "    denoised_2 = []\n",
    "    for frame in T:\n",
    "        mean = np.mean(frame)\n",
    "        std = np.std(frame)\n",
    "        pred = denormalize(model2.predict(normalize(frame, mean, std), axes='YX', normalizer=None), mean, std)\n",
    "        denoised_2.append(pred)\n",
    "    io.imsave(f'{save_dir_C2}/{C2_names[counter]}.tif', np.asarray(denoised_2))\n",
    "    counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C2_names = []\n",
    "#for file in C1_files:\n",
    "#    C1_names.append(file.stem)\n",
    "#    T1 = imread(str(file))\n",
    "#    C1_ims.append(T1)\n",
    "for file in tqdm(C2_files):\n",
    "    C2_names.append(file.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
